{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî¨ Larynx segmentation using transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üì¶ Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('utils')\n",
    "from utils.notebook_utils import generate_model_name, get_nb_filename\n",
    "from utils.train_logs import display_metrics, pretty_time\n",
    "from utils.metrics import Metrics\n",
    "from utils.preprocessing import preprocess_masks, split_dataset\n",
    "from utils.plotting import plot_image_with_mask\n",
    "from utils.dataset import CleDataset, custom_collate\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tabulate\n",
    "from time import perf_counter\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader  \n",
    "from tqdm.auto import tqdm as tq\n",
    "from torchvision.transforms import v2 as T\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from transformers import SegformerForSemanticSegmentation, SegformerConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üî¢ Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = torch.float32\n",
    "img_size = (424, 530)\n",
    "num_classes = 3\n",
    "batch_size = 2\n",
    "\n",
    "background_class = 0\n",
    "trachea_class = 1\n",
    "supraglottis_class = 2\n",
    "\n",
    "use_batch_transforms = True\n",
    "mix_batch_transforms = False\n",
    "\n",
    "actual_batch_size = 2 * batch_size if use_batch_transforms else batch_size\n",
    "\n",
    "model_filename = generate_model_name(get_nb_filename())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use CUDA/GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìÇ Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define paths for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = '/path/to/data/folder'\n",
    "path = f'data/{folder_name}'\n",
    "\n",
    "data_path = Path(path)\n",
    "images = data_path/'images'\n",
    "mask_data = data_path/'result.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecting images with their corresponding masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = preprocess_masks(mask_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = split_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üõ†Ô∏è Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creates a DataLoader object from a dataset\n",
    "'''\n",
    "def create_dataloader(dataset):\n",
    "  return DataLoader(\n",
    "    CleDataset(\n",
    "      images_with_annotations=dataset,\n",
    "      data_folder=images,\n",
    "      img_size=img_size,\n",
    "      batch_size=batch_size,\n",
    "      use_batch_transforms=use_batch_transforms,\n",
    "      mix_batch_transforms=mix_batch_transforms\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=custom_collate\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Upsample/resizes the logits to the original image size\n",
    "'''\n",
    "def upsamle_logits(logits):\n",
    "  return T.Resize(size=img_size, interpolation=InterpolationMode.BILINEAR)(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîÑ DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = create_dataloader(train)\n",
    "valid_dataloader = create_dataloader(valid)\n",
    "test_dataloader = create_dataloader(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the length of the data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train batches: {len(train_dataloader)}\")\n",
    "print(f\"Valid batches: {len(valid_dataloader)}\")\n",
    "print(f\"Test batches: {len(test_dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üëÅ Display images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display sample training image and mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = iter(train_dataloader)\n",
    "train_features, train_labels = next(train_iterator)\n",
    "\n",
    "for i in range(len(train_features)):\n",
    "  img = train_features[i].squeeze()\n",
    "  label = train_labels[i]\n",
    "  plot_image_with_mask(img, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß† Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the configuration of the transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MiT-b2\n",
    "config = SegformerConfig(\n",
    "    image_size=img_size,\n",
    "    num_channels=3,\n",
    "    num_labels=3,\n",
    "    depths=[3, 4, 6, 3],\n",
    "    hidden_sizes=[64, 128, 320, 512],\n",
    "    decoder_hidden_size=768\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SegformerForSemanticSegmentation(config).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the optimizer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 2000\n",
    "early_stop_limit = 10\n",
    "epochs_since_improvement = 0\n",
    "\n",
    "epochs_list, train_loss_list, valid_loss_list, valid_loss_decreased_list, dice_list, precision_list, recall_list, f1_list, lr_rate_list, duration_list, iou_list = [], [], [], [], [], [], [], [], [], [], []\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    clear_output(wait=False)\n",
    "    display_metrics([epochs_list, valid_loss_decreased_list, train_loss_list, valid_loss_list, dice_list, iou_list, f1_list, precision_list, recall_list, duration_list])\n",
    "    train_loss, valid_loss = 0., 0.\n",
    "    metrics = Metrics(device)\n",
    "\n",
    "    model.train()\n",
    "    bar = tq(train_dataloader, postfix={\"train_loss\":0.})\n",
    "    epochs_list.append(epoch)\n",
    "    start_time = perf_counter()\n",
    "\n",
    "    for data, target in bar:\n",
    "        data.requires_grad = True\n",
    "        target.requires_grad = True\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        data = data.to(device=device)\n",
    "        target = target.to(device=device)\n",
    "        output = model(data, labels=target.argmax(dim=1))\n",
    "\n",
    "        loss = output.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        bar.set_postfix({\"train_loss\":loss.item()})\n",
    "\n",
    "    model.eval()\n",
    "    del data, target\n",
    "    with torch.no_grad():\n",
    "        bar = tq(valid_dataloader, postfix={\"valid_loss\":0.0, \"dice_score\":0.0})\n",
    "        for data, target in bar:\n",
    "            data = data.to(device=device)\n",
    "            target = target.to(device=device)\n",
    "            output = model(data, labels=target.argmax(dim=1))\n",
    "\n",
    "            loss = output.loss\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "            logits_upsampled = upsamle_logits(output.logits)\n",
    "            logits_soft = torch.softmax(logits_upsampled, dim=1)\n",
    "            \n",
    "            metrics.accumulate(logits_soft, target)\n",
    "\n",
    "            bar.set_postfix(ordered_dict={\"valid_loss\": loss.item()})\n",
    "\n",
    "    # Calculate average losses and metrics\n",
    "    train_loss = train_loss/len(train_dataloader)\n",
    "    valid_loss = valid_loss/len(valid_dataloader)\n",
    "    valid_loss_decreased = valid_loss <= valid_loss_min\n",
    "    dice_score, iou_score, precision, recall, f1 = metrics.get_value_and_reset(n_batches=len(valid_dataloader))\n",
    "\n",
    "    # Append losses to lists\n",
    "    train_loss_list.append(train_loss)\n",
    "    valid_loss_list.append(valid_loss)\n",
    "    valid_loss_decreased_list.append(valid_loss_decreased)\n",
    "    dice_list.append(dice_score)\n",
    "    iou_list.append(iou_score)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "    lr_rate_list.append([param_group['lr'] for param_group in optimizer.param_groups])\n",
    "    duration_list.append(perf_counter() - start_time)\n",
    "    \n",
    "    # Save model if validation loss has decreased\n",
    "    if valid_loss_decreased:\n",
    "        torch.save(model.state_dict(), model_filename)\n",
    "        valid_loss_min = valid_loss\n",
    "        epochs_since_improvement = 0\n",
    "    else:\n",
    "        epochs_since_improvement += 1\n",
    "        if epochs_since_improvement >= early_stop_limit:\n",
    "            total_duration_to_stop = sum(duration_list[:-early_stop_limit])\n",
    "            clear_output(wait=False)\n",
    "            print(f\"üõë Early stopping. No improvement since epoch {epoch - early_stop_limit} epochs. Duration: {pretty_time(total_duration_to_stop)}\")\n",
    "            display_metrics([epochs_list, valid_loss_decreased_list, train_loss_list, valid_loss_list, dice_list, iou_list, f1_list, precision_list, recall_list, duration_list])\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Loss graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section displays graphs for loss and the metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_to_exclude = 0\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(train_loss_list[epochs_to_exclude:],  marker='o', label=\"Training Loss\", color='blue')\n",
    "plt.plot(valid_loss_list[epochs_to_exclude:],  marker='o', label=\"Validation Loss\", color='orange')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training Loss', 'Validation Loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision, Recall, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_to_exclude = 0\n",
    "index = 0\n",
    "\n",
    "precision_list_cpu = [tensor.cpu()[index] for tensor in precision_list]\n",
    "recall_list_cpu = [tensor.cpu()[index] for tensor in recall_list]\n",
    "f1_list_cpu = [tensor.cpu()[index] for tensor in f1_list]\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.title('Tranchea')\n",
    "plt.plot(precision_list_cpu[epochs_to_exclude:],  marker='o', label=\"Precision\", color='green')\n",
    "plt.plot(recall_list_cpu[epochs_to_exclude:],  marker='o', label=\"Recall\", color='red')\n",
    "plt.plot(f1_list_cpu[epochs_to_exclude:],  marker='o', label=\"F1\", color='black')\n",
    "plt.legend(['Precision', 'Recall', 'F1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_to_exclude = 0\n",
    "index = 1\n",
    "\n",
    "precision_list_cpu = [tensor.cpu()[index] for tensor in precision_list]\n",
    "recall_list_cpu = [tensor.cpu()[index] for tensor in recall_list]\n",
    "f1_list_cpu = [tensor.cpu()[index] for tensor in f1_list]\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.title('Supraglottis')\n",
    "plt.plot(precision_list_cpu[epochs_to_exclude:],  marker='o', label=\"Precision\", color='green')\n",
    "plt.plot(recall_list_cpu[epochs_to_exclude:],  marker='o', label=\"Recall\", color='red')\n",
    "plt.plot(f1_list_cpu[epochs_to_exclude:],  marker='o', label=\"F1\", color='black')\n",
    "plt.legend(['Precision', 'Recall', 'F1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "dice_list_1_cpu = [tensor.cpu()[index] for tensor in dice_list]\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(dice_list_1_cpu)\n",
    "plt.title('Tranchea Dice score')\n",
    "plt.ylabel('Dice')\n",
    "plt.legend(['Dice score'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "dice_list_2_cpu = [tensor.cpu()[index] for tensor in dice_list]\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(dice_list_2_cpu)\n",
    "plt.title('Supraglottis Dice score')\n",
    "plt.ylabel('Dice')\n",
    "plt.legend(['Dice score'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Calculates the dice score for a single prediction\n",
    "'''\n",
    "def dice_score_single(pred, y, dim):\n",
    "  prediction, target = torch.softmax(pred, dim=0).argmax(dim=0), y[dim, :]\n",
    "  prediction = torch.where(prediction == dim, 1, 0)\n",
    "  inter = torch.sum(prediction * target).item()\n",
    "  union = torch.sum(prediction).item() + torch.sum(target).item()\n",
    "  return 2. * inter/union if union > 0 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_test_images = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model by displaying the predicted mask and calculating the metrics for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_to_test = test_dataloader\n",
    "iterator = iter(dataloader_to_test)\n",
    "metrics = Metrics(device)\n",
    "\n",
    "for batch in range(len(dataloader_to_test)):\n",
    "  img_batch, label_batch = next(iterator)\n",
    "  if len(img_batch) != actual_batch_size: break\n",
    "  logits = model(img_batch.to(device=device)).logits.cpu()\n",
    "  logits_upsampled = upsamle_logits(logits)\n",
    "  logits_soft = torch.softmax(logits_upsampled, dim=1)\n",
    "\n",
    "  metrics.accumulate(logits_soft, label_batch)\n",
    "\n",
    "  if plot_test_images:\n",
    "    for i in range(len(img_batch)):\n",
    "      # Plot\n",
    "        print(f\"Batch {batch}, image {i}\")\n",
    "        pred_argmax = logits_soft[i].argmax(dim=0)\n",
    "        background = torch.where(pred_argmax == background_class, 1, 0)\n",
    "        trachea_pixels = torch.where(pred_argmax == trachea_class, 1, 0)\n",
    "        supraglottis_pixels = torch.where(pred_argmax == supraglottis_class, 1, 0)\n",
    "        plot_image_with_mask(img_batch[i], [background, trachea_pixels, supraglottis_pixels])\n",
    "\n",
    "        # Single dice\n",
    "        single_dice_1 = dice_score_single(logits_soft[i], label_batch[i], dim=1)\n",
    "        single_dice_2 = dice_score_single(logits_soft[i], label_batch[i], dim=2)\n",
    "        print(f\"Single dice (tranchea): {single_dice_1}\")\n",
    "        print(f\"Single dice (supraglottis): {single_dice_2}\\n\")\n",
    "\n",
    "dice_score, iou_score, precision, recall, f1 = metrics.get_value_and_reset(n_batches=len(dataloader_to_test))\n",
    "\n",
    "data = [\n",
    "        [\"Metric\", \"Trachea\", \"Supraglottis\"],\n",
    "        [\"Dice score\", dice_score[0], dice_score[1]],\n",
    "        [\"IoU\", iou_score[0], iou_score[1]],\n",
    "        [\"F1\", f1[0], f1[1]],\n",
    "        [\"Precision\", precision[0], precision[1]],\n",
    "        [\"Recall\", recall[0], recall[1]]\n",
    "       ]\n",
    "table = tabulate.tabulate(data, tablefmt='html', headers='firstrow', floatfmt='0.4f')\n",
    "table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
